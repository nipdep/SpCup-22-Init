{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "aasits_part2c.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! apt-get install libsox-fmt-all\n",
        "# install the sox command line tool\n",
        "! apt-get install sox\n",
        "# install pysox\n",
        "! pip install sox\n",
        "\n",
        "! pip install torchcontrib\n",
        "! pip install neptune-client"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-17T16:59:30.878253Z",
          "iopub.execute_input": "2022-03-17T16:59:30.878573Z",
          "iopub.status.idle": "2022-03-17T16:59:41.616952Z",
          "shell.execute_reply.started": "2022-03-17T16:59:30.878494Z",
          "shell.execute_reply": "2022-03-17T16:59:41.616132Z"
        },
        "trusted": true,
        "id": "69cCX5B0opxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import requests\n",
        "from importlib import import_module\n",
        "from pathlib import Path\n",
        "from shutil import copy\n",
        "from typing import Dict, List, Union\n",
        "import pandas as pd\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import neptune.new as neptune\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "from torchcontrib.optim import SWA\n",
        "import torchaudio\n",
        "\n",
        "from data_utilsV2 import (Dataset_ASVspoof2019_train, genSpoof_list)\n",
        "from evaluation import calculate_tDCF_EER\n",
        "from utils import create_optimizer, seed_worker, set_seed, str_to_bool\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "seed = 123\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-17T16:59:41.618889Z",
          "iopub.execute_input": "2022-03-17T16:59:41.619143Z",
          "iopub.status.idle": "2022-03-17T16:59:43.990838Z",
          "shell.execute_reply.started": "2022-03-17T16:59:41.619111Z",
          "shell.execute_reply": "2022-03-17T16:59:43.990063Z"
        },
        "trusted": true,
        "id": "_UMe6SDjopxR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tracker = neptune.init(\n",
        "    project=\"nipdep/sp-cup\",\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJkNWJjMDdhNC05NWY5LTQwNWQtYTQyNi0zNjNmYmYwZDg3M2YifQ==\",\n",
        ")  # your credentials"
      ],
      "metadata": {
        "id": "Lc3z-kS8tiop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13167305-ae84-4297-88d3-179af705b9be"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/nipdep/sp-cup/e/SPCUP-79\n",
            "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_SAMPLE_DIR = \"_assets\"\n",
        "SAMPLE_RIR_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav\"  # noqa: E501\n",
        "SAMPLE_RIR_PATH = os.path.join(_SAMPLE_DIR, \"rir.wav\")\n",
        "\n",
        "SAMPLE_WAV_SPEECH_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"  # noqa: E501\n",
        "SAMPLE_WAV_SPEECH_PATH = os.path.join(_SAMPLE_DIR, \"speech.wav\")\n",
        "\n",
        "SAMPLE_NOISE_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav\"  # noqa: E501\n",
        "SAMPLE_NOISE_PATH = os.path.join(_SAMPLE_DIR, \"bg.wav\")\n",
        "\n",
        "os.makedirs(_SAMPLE_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "7e5On66sqjoX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _fetch_data():\n",
        "    uri = [\n",
        "        (SAMPLE_RIR_URL, SAMPLE_RIR_PATH),\n",
        "        (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n",
        "        (SAMPLE_NOISE_URL, SAMPLE_NOISE_PATH),\n",
        "    ]\n",
        "    for url, path in uri:\n",
        "        with open(path, \"wb\") as file_:\n",
        "            file_.write(requests.get(url).content)\n",
        "\n",
        "\n",
        "_fetch_data()"
      ],
      "metadata": {
        "id": "E045oOK9qkf6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_sample(path, resample=None):\n",
        "    effects = [[\"remix\", \"1\"]]\n",
        "    if resample:\n",
        "        effects.extend(\n",
        "            [\n",
        "                [\"lowpass\", f\"{resample // 2}\"],\n",
        "                [\"rate\", f\"{resample}\"],\n",
        "            ]\n",
        "        )\n",
        "    return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
        "\n",
        "def get_noise_sample(*, resample=None):\n",
        "    return _get_sample(SAMPLE_NOISE_PATH, resample=resample)\n",
        "\n",
        "noise, _ = get_noise_sample()"
      ],
      "metadata": {
        "id": "H6sMU1cUqsix"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__File Operations__"
      ],
      "metadata": {
        "id": "IOfiUgpiopxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget \"https://www.dropbox.com/s/36yqmymkva2bwdi/spcup_2022_training_part1.zip?dl=1\" -c -O 'spcup_2022_training_part1.zip'\n",
        "! wget \"https://www.dropbox.com/s/wsmlthhri29fb79/spcup_2022_unseen.zip?dl=1\" -c -O 'spcup_2022_unseen.zip'\n",
        "\n",
        "!unzip \"./spcup_2022_training_part1.zip\" -d \"./spcup_2022_training/\"\n",
        "!unzip \"./spcup_2022_unseen.zip\" -d \"./spcup_2022_unseen/\"\n",
        "\n",
        "!rm \"./spcup_2022_training_part1.zip\"\n",
        "!rm \"./spcup_2022_unseen.zip\"\n",
        "\n",
        "df1 = pd.read_csv('./spcup_2022_training/spcup_2022_training_part1/labels.csv')\n",
        "df2 = pd.read_csv('./spcup_2022_unseen/spcup_2022_unseen/labels.csv')\n",
        "df3 = pd.concat([df1, df2]).sample(frac=1)\n",
        "\n",
        "df3.to_csv('./final_labels.csv', index=False)\n",
        "!rm './spcup_2022_unseen/spcup_2022_unseen/labels.csv'\n",
        "\n",
        "!cp -a \"./spcup_2022_unseen/spcup_2022_unseen/\". \"./spcup_2022_training/spcup_2022_training_part1/\"\n",
        "\n",
        "! wget \"https://www.dropbox.com/s/zylz07o2z0x308g/spcup_2022_eval_part2.zip?dl=1\" -c -O \"./spcup_2022_eval_part2.zip\"\n",
        "! unzip \"./spcup_2022_eval_part2.zip\" -d \"./spcup_2022_eval_part2/\"\n",
        "!rm \"./spcup_2022_eval_part2.zip\"\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "HdZ-DIB5opxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***"
      ],
      "metadata": {
        "id": "trDTGk9KopxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model_config: Dict, device: torch.device):\n",
        "    \"\"\"Define DNN model architecture\"\"\"\n",
        "    module = import_module(\"{}\".format(model_config[\"architecture\"]))\n",
        "    _model = getattr(module, \"Model\")\n",
        "    model = _model(model_config).to(device)\n",
        "    nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
        "    print(\"no. model params:{}\".format(nb_params))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-17T17:03:42.011152Z",
          "iopub.execute_input": "2022-03-17T17:03:42.011483Z",
          "iopub.status.idle": "2022-03-17T17:03:42.018706Z",
          "shell.execute_reply.started": "2022-03-17T17:03:42.01138Z",
          "shell.execute_reply": "2022-03-17T17:03:42.016274Z"
        },
        "trusted": true,
        "id": "9Xy6Q8ACopxX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(\n",
        "        database_path: str,\n",
        "        label_path: str,\n",
        "        config: dict) -> List[torch.utils.data.DataLoader]:\n",
        "    \"\"\"Make PyTorch DataLoaders for train / developement / evaluation\"\"\"\n",
        "    # == dropping part ==\n",
        "    # track = config[\"track\"]\n",
        "    # prefix_2019 = \"ASVspoof2019.{}\".format(track)\n",
        "\n",
        "    # trn_database_path = database_path / \"ASVspoof2019_{}_train/\".format(track)\n",
        "    # dev_database_path = database_path / \"ASVspoof2019_{}_dev/\".format(track)\n",
        "    # eval_database_path = database_path / \"ASVspoof2019_{}_eval/\".format(track)\n",
        "\n",
        "    # trn_list_path = (database_path /\n",
        "    #                  \"ASVspoof2019_{}_cm_protocols/{}.cm.train.trn.txt\".format(\n",
        "    #                      track, prefix_2019))\n",
        "    # dev_trial_path = (database_path /\n",
        "    #                   \"ASVspoof2019_{}_cm_protocols/{}.cm.dev.trl.txt\".format(\n",
        "    #                       track, prefix_2019))\n",
        "    # eval_trial_path = (\n",
        "    #     database_path /\n",
        "    #     \"ASVspoof2019_{}_cm_protocols/{}.cm.eval.trl.txt\".format(\n",
        "    #         track, prefix_2019))\n",
        "\n",
        "    # d_label_trn, file_train = genSpoof_list(dir_meta=trn_list_path,\n",
        "    #                                         is_train=True,\n",
        "    #                                         is_eval=False)\n",
        "    # print(\"no. training files:\", len(file_train))\n",
        "    # =====================\n",
        "\n",
        "    label_df = pd.read_csv(label_path)\n",
        "    X, y = label_df['track'].values, label_df['algorithm'].values\n",
        "    # stratified split dataset into train-validation\n",
        "    # set param as config[\"split_ratio\"]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
        "\n",
        "\n",
        "    train_set = Dataset_ASVspoof2019_train(list_IDs=X_train,\n",
        "                                           labels=y_train,\n",
        "                                           base_dir=database_path, is_train=True, is_dest=True)\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "    trn_loader = DataLoader(train_set,\n",
        "                            batch_size=config[\"batch_size\"],\n",
        "                            shuffle=True,\n",
        "                            drop_last=True,\n",
        "                            pin_memory=True,\n",
        "                            worker_init_fn=seed_worker,\n",
        "                            generator=gen)\n",
        "\n",
        "    # # == test dataset not yet given ==\n",
        "\n",
        "    # _, file_dev = genSpoof_list(dir_meta=dev_trial_path,\n",
        "    #                             is_train=False,\n",
        "    #                             is_eval=False)\n",
        "    # print(\"no. validation files:\", len(file_dev))\n",
        "\n",
        "#     dev_set = Dataset_ASVspoof2019_devNeval(list_IDs=config['file_dev'],\n",
        "#                                             base_dir=config['dev_database_path'])\n",
        "#     dev_loader = DataLoader(dev_set,\n",
        "#                             batch_size=config[\"batch_size\"],\n",
        "#                             shuffle=False,\n",
        "#                             drop_last=False,\n",
        "#                             pin_memory=True)\n",
        "    # =================================\n",
        "\n",
        "    # == validation dataset {updated} == \n",
        "\n",
        "    eval_set = Dataset_ASVspoof2019_train(list_IDs=X_test,\n",
        "                                           labels=y_test,\n",
        "                                           base_dir=database_path, is_train=False, is_dest=True)\n",
        "    eval_loader = DataLoader(eval_set,\n",
        "                             batch_size=config[\"batch_size\"],\n",
        "                             shuffle=False,\n",
        "                             drop_last=False,\n",
        "                             pin_memory=True,\n",
        "                             worker_init_fn=seed_worker,\n",
        "                             generator=gen)\n",
        "\n",
        "    return trn_loader, eval_loader"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-17T17:03:42.398269Z",
          "iopub.execute_input": "2022-03-17T17:03:42.39868Z",
          "iopub.status.idle": "2022-03-17T17:03:42.410445Z",
          "shell.execute_reply.started": "2022-03-17T17:03:42.398642Z",
          "shell.execute_reply": "2022-03-17T17:03:42.409597Z"
        },
        "trusted": true,
        "id": "gUPpdSmlopxY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def produce_evaluation_file(\n",
        "    data_loader: DataLoader,\n",
        "    model,\n",
        "    device: torch.device,\n",
        "    save_path: str,\n",
        "    trial_path: str) -> None:\n",
        "    \"\"\"Perform evaluation and save the score to a file\"\"\"\n",
        "    model.eval()\n",
        "    with open(trial_path, \"r\") as f_trl:\n",
        "        trial_lines = f_trl.readlines()\n",
        "    fname_list = []\n",
        "    score_list = []\n",
        "    for batch_x, utt_id in data_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        with torch.no_grad():\n",
        "            _, batch_out = model(batch_x)\n",
        "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
        "        # add outputs\n",
        "        fname_list.extend(utt_id)\n",
        "        score_list.extend(batch_score.tolist())\n",
        "\n",
        "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
        "    with open(save_path, \"w\") as fh:\n",
        "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
        "            _, utt_id, _, src, key = trl.strip().split(' ')\n",
        "            assert fn == utt_id\n",
        "            fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n",
        "    print(\"Scores saved to {}\".format(save_path))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-17T17:03:47.214153Z",
          "iopub.execute_input": "2022-03-17T17:03:47.214682Z",
          "iopub.status.idle": "2022-03-17T17:03:47.225516Z",
          "shell.execute_reply.started": "2022-03-17T17:03:47.214636Z",
          "shell.execute_reply": "2022-03-17T17:03:47.224694Z"
        },
        "trusted": true,
        "id": "GXw6XOH3opxb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(\n",
        "    trn_loader: DataLoader,\n",
        "    model,\n",
        "    optim: Union[torch.optim.SGD, torch.optim.Adam],\n",
        "    device: torch.device,\n",
        "    scheduler: torch.optim.lr_scheduler,\n",
        "    config: argparse.Namespace):\n",
        "    \"\"\"Train the model for one epoch\"\"\"\n",
        "    \n",
        "    running_loss = 0\n",
        "    num_total = 0.0\n",
        "    train_acc, correct_train, target_count = 0, 0, 0\n",
        "    ii = 0\n",
        "    model.train()\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    # set objective (Loss) functions\n",
        "    weight = torch.FloatTensor([0.1, 0.9]).to(device)\n",
        "    # criterion = nn.CrossEntropyLoss(weight=weight)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with tqdm(trn_loader, unit=\"batch\") as tepoch:\n",
        "      for batch_x, batch_y in tepoch:\n",
        "          batch_size = batch_x.size(0)\n",
        "          num_total += batch_size\n",
        "          ii += 1\n",
        "          batch_x = batch_x.to(device)\n",
        "          batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
        "          batch_y = batch_y.view(-1).to(device)\n",
        "          with autocast():\n",
        "            _, batch_out = model(batch_x)\n",
        "            batch_loss = criterion(batch_out, batch_y)\n",
        "            running_loss += batch_loss.item() * batch_size\n",
        "          optim.zero_grad()\n",
        "  #         scaler.scale(batch_loss).backward()\n",
        "          batch_loss.backward()\n",
        "  #         scaler.step(optim)\n",
        "  #         scaler.update()\n",
        "          optim.step()\n",
        "\n",
        "          # print(batch_loss.cpu().numpy())\n",
        "          # print(batch_loss.item() * batch_size, type(batch_loss.item() * batch_size))\n",
        "          \n",
        "\n",
        "          if config[\"optim_config\"][\"scheduler\"] in [\"cosine\", \"keras_decay\"]:\n",
        "              scheduler.step()\n",
        "          elif scheduler is None:\n",
        "              pass\n",
        "          else:\n",
        "              raise ValueError(\"scheduler error, got:{}\".format(scheduler))\n",
        "          \n",
        "          # accuracy\n",
        "          _, predicted = torch.max(batch_out.data, 1)\n",
        "          target_count += batch_y.size(0)\n",
        "          correct_train += (batch_y == predicted).sum().item()\n",
        "          train_acc = (100 * correct_train) / target_count\n",
        "\n",
        "    running_loss /= num_total\n",
        "    return running_loss, train_acc"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-17T17:30:23.138469Z",
          "iopub.execute_input": "2022-03-17T17:30:23.138756Z",
          "iopub.status.idle": "2022-03-17T17:30:23.151125Z",
          "shell.execute_reply.started": "2022-03-17T17:30:23.138725Z",
          "shell.execute_reply": "2022-03-17T17:30:23.150447Z"
        },
        "trusted": true,
        "id": "BcYUVGCfopxc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_epoch(\n",
        "    trn_loader: DataLoader,\n",
        "    model,\n",
        "    device: torch.device,\n",
        "    config: argparse.Namespace):\n",
        "    \"\"\"Train the model for one epoch\"\"\"\n",
        "    running_loss = 0\n",
        "    num_total = 0.0\n",
        "    val_acc, correct_train, target_count = 0, 0, 0\n",
        "    ii = 0\n",
        "    model.eval()\n",
        "\n",
        "    # set objective (Loss) functions\n",
        "    weight = torch.FloatTensor([0.1, 0.9]).to(device)\n",
        "    # criterion = nn.CrossEntropyLoss(weight=weight)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with tqdm(trn_loader, unit=\"batch\") as tepoch:\n",
        "      for batch_x, batch_y in tepoch:\n",
        "          batch_size = batch_x.size(0)\n",
        "          num_total += batch_size\n",
        "          ii += 1\n",
        "          batch_x = batch_x.to(device)\n",
        "          # batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
        "          batch_y = batch_y.view(-1).to(device)\n",
        "          with autocast():\n",
        "            _, batch_out = model(batch_x) #model(batch_x, Freq_aug=str_to_bool(config[\"freq_aug\"]))\n",
        "            batch_loss = criterion(batch_out, batch_y)\n",
        "            running_loss += batch_loss.item() * batch_size\n",
        "          \n",
        "          # accuracy\n",
        "          _, predicted = torch.max(batch_out.data, 1)\n",
        "          target_count += batch_y.size(0)\n",
        "          correct_train += (batch_y == predicted).sum().item()\n",
        "          val_acc = (100 * correct_train) / target_count\n",
        "        \n",
        "    running_loss /= num_total\n",
        "    return running_loss, val_acc"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-17T17:30:30.349514Z",
          "iopub.execute_input": "2022-03-17T17:30:30.350055Z",
          "iopub.status.idle": "2022-03-17T17:30:30.360683Z",
          "shell.execute_reply.started": "2022-03-17T17:30:30.350016Z",
          "shell.execute_reply": "2022-03-17T17:30:30.360031Z"
        },
        "trusted": true,
        "id": "JDQb3_73opxc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('./spcup_2022_eval_part2/spcup_2022_eval_part2/labels_eval_part2.csv')\n",
        "test_list = test_df['track'].values\n",
        "test_list"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-17T17:30:30.364422Z",
          "iopub.execute_input": "2022-03-17T17:30:30.364606Z",
          "iopub.status.idle": "2022-03-17T17:30:30.381896Z",
          "shell.execute_reply.started": "2022-03-17T17:30:30.364585Z",
          "shell.execute_reply": "2022-03-17T17:30:30.381177Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM4-sfQmopxd",
        "outputId": "a0373763-15df-43a4-dad5-074d3e233023"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['36d06279048026b1059236c4b5024f78.wav',\n",
              "       '49550c0090367cd3bf8353b7c4a8f62a.wav',\n",
              "       'b336ac2a2b8cf99ff922bbd3d29a68a3.wav', ...,\n",
              "       'a9df966d00b7605602c11ae840f58453.wav',\n",
              "       '139db88a8579c14fd22013e19897b015.wav',\n",
              "       '803baa31a5ee19ebd30bd9d71031f95d.wav'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \n",
        "    \"database_path\": \"./spcup_2022_training/spcup_2022_training_part1/\",\n",
        "    \"label_path\": \"./final_labels.csv\",\n",
        "    \"asv_score_path\": \"ASVspoof2019_LA_asv_scores/ASVspoof2019.LA.asv.eval.gi.trl.scores.txt\",\n",
        "    \"model_path\": \"./models/weights/AASIST.pth\",\n",
        "    \"dev_database_path\": './spcup_2022_eval_part1/spcup_2022_eval_part1/',\n",
        "    \"file_dev\": test_list,\n",
        "    \"batch_size\": 16,\n",
        "    \"num_epochs\": 16,\n",
        "    \"loss\": \"CCE\",\n",
        "    \"track\": \"LA\",\n",
        "    \"eval_all_best\": \"True\",\n",
        "    \"eval_output\": \"eval_scores_using_best_dev_model.txt\",\n",
        "    \"cudnn_deterministic_toggle\": \"True\",\n",
        "    \"cudnn_benchmark_toggle\": \"False\",\n",
        "    \"model_config\": {\n",
        "        \"architecture\": \"aasist\",\n",
        "        \"nb_samp\": 64600,\n",
        "        \"first_conv\": 128,\n",
        "        \"filts\": [70, [1, 32], [32, 32], [32, 64], [64, 64]],\n",
        "        \"gat_dims\": [64, 32],\n",
        "        \"pool_ratios\": [0.5, 0.7, 0.5, 0.5],\n",
        "        \"temperatures\": [2.0, 2.0, 100.0, 100.0]\n",
        "    },\n",
        "    \"optim_config\": {\n",
        "        \"optimizer\": \"adam\", \n",
        "        \"amsgrad\": \"False\",\n",
        "        \"base_lr\": 0.0001,\n",
        "        \"lr_min\": 0.00005,\n",
        "        \"betas\": [0.9, 0.999],\n",
        "        \"weight_decay\": 0.0001,\n",
        "        \"scheduler\": \"cosine\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-17T17:30:32.62647Z",
          "iopub.execute_input": "2022-03-17T17:30:32.626721Z",
          "iopub.status.idle": "2022-03-17T17:30:32.635134Z",
          "shell.execute_reply.started": "2022-03-17T17:30:32.626693Z",
          "shell.execute_reply": "2022-03-17T17:30:32.634196Z"
        },
        "trusted": true,
        "id": "vUTAVS6topxd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tracker[\"parameters\"] = config"
      ],
      "metadata": {
        "id": "b9tC0oVBtq65"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = argparse.Namespace()\n",
        "args.config = config\n",
        "args.seed = seed\n",
        "args.output_dir = './tmp/out'\n",
        "args.comment = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-17T17:30:32.636749Z",
          "iopub.execute_input": "2022-03-17T17:30:32.637182Z",
          "iopub.status.idle": "2022-03-17T17:30:32.646868Z",
          "shell.execute_reply.started": "2022-03-17T17:30:32.637146Z",
          "shell.execute_reply": "2022-03-17T17:30:32.646086Z"
        },
        "trusted": true,
        "id": "_KTsayj_opxd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(args):\n",
        "\n",
        "    # define database related paths\n",
        "    output_dir = Path(args.output_dir)\n",
        "    database_path = Path(config[\"database_path\"])\n",
        "    label_path = Path(config['label_path'])\n",
        "\n",
        "    # set device\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(\"Device: {}\".format(device))\n",
        "    # if device == \"cpu\":\n",
        "    #     raise ValueError(\"GPU not detected!\")\n",
        "\n",
        "    # define model architecture\n",
        "    model_config = args.config[\"model_config\"]\n",
        "    model = get_model(model_config, device)\n",
        "\n",
        "    # define dataloaders\n",
        "    trn_loader, eval_loader = get_loader(database_path, label_path, config)\n",
        "\n",
        "    # get optimizer and scheduler\n",
        "    optim_config = config[\"optim_config\"]\n",
        "    optim_config[\"epochs\"] = config[\"num_epochs\"]\n",
        "    optim_config[\"steps_per_epoch\"] = len(trn_loader)\n",
        "    optimizer, scheduler = create_optimizer(model.parameters(), optim_config)\n",
        "    optimizer_swa = SWA(optimizer)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    # Training\n",
        "    for epoch in range(config[\"num_epochs\"]):\n",
        "        print(\"Start training epoch{:03d}\".format(epoch))\n",
        "        training_loss, training_acc = train_epoch(trn_loader, model, optimizer, device,\n",
        "                                   scheduler, config)\n",
        "        eval_loss, eval_acc = eval_epoch(eval_loader, model, device, config)\n",
        "        \n",
        "        if eval_acc > best_acc: \n",
        "            torch.save(model.state_dict(), \"./best_audio_model.pth\")\n",
        "        tracker['train/loss'].log(training_loss)\n",
        "        tracker['train/acc'].log(training_acc)\n",
        "        tracker['eval/loss'].log(eval_loss)\n",
        "        tracker['eval/acc'].log(eval_acc)\n",
        "        print(f'[{epoch}] Training Loss : {training_loss} / Training Accuracy : {training_acc} | Eval Loss : {eval_loss} / Eval Accuracy : {eval_acc}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-17T17:30:32.648072Z",
          "iopub.execute_input": "2022-03-17T17:30:32.649815Z",
          "iopub.status.idle": "2022-03-17T17:30:32.660449Z",
          "shell.execute_reply.started": "2022-03-17T17:30:32.649714Z",
          "shell.execute_reply": "2022-03-17T17:30:32.659777Z"
        },
        "trusted": true,
        "id": "07LnUqGzopxd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(args)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-17T17:30:32.661938Z",
          "iopub.execute_input": "2022-03-17T17:30:32.662437Z",
          "iopub.status.idle": "2022-03-17T17:45:47.842235Z",
          "shell.execute_reply.started": "2022-03-17T17:30:32.6624Z",
          "shell.execute_reply": "2022-03-17T17:45:47.839868Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "jdjwikZjopxe",
        "outputId": "3083cd78-d914-4d2d-c7ee-554f75318908"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "no. model params:298510\n",
            "Start training epoch000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 2/300 [00:13<33:01,  6.65s/batch]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b3f47c9a9b7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-27a9f8a91277>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start training epoch{:03d}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         training_loss, training_acc = train_epoch(trn_loader, model, optimizer, device,\n\u001b[0;32m---> 33\u001b[0;31m                                    scheduler, config)\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0meval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-28b0070a7aca>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(trn_loader, model, optim, device, scheduler, config)\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;31m#         scaler.step(optim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;31m#         scaler.update()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m           \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m           \u001b[0;31m# print(batch_loss.cpu().numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device: {}\".format(device))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-16T15:19:47.406867Z",
          "iopub.execute_input": "2022-03-16T15:19:47.407192Z",
          "iopub.status.idle": "2022-03-16T15:19:47.416927Z",
          "shell.execute_reply.started": "2022-03-16T15:19:47.40716Z",
          "shell.execute_reply": "2022-03-16T15:19:47.41573Z"
        },
        "trusted": true,
        "id": "tF885Htmopxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_path = './best_audio_model.pth'\n",
        "pred_model = get_model(args.config[\"model_config\"], device)\n",
        "pred_model.load_state_dict(torch.load(best_path), strict=False)\n",
        "pred_model = pred_model.to(device)\n",
        "pred_model.eval()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-16T15:19:48.671624Z",
          "iopub.execute_input": "2022-03-16T15:19:48.671966Z",
          "iopub.status.idle": "2022-03-16T15:19:48.785284Z",
          "shell.execute_reply.started": "2022-03-16T15:19:48.671907Z",
          "shell.execute_reply": "2022-03-16T15:19:48.783944Z"
        },
        "trusted": true,
        "id": "2CUJvFVropxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(x, max_len=64600):\n",
        "    x_len = x.shape[0]\n",
        "    if x_len >= max_len:\n",
        "        return x[:max_len]\n",
        "    # need to pad\n",
        "    num_repeats = int(max_len / x_len) + 1\n",
        "    padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]\n",
        "    return padded_x\n",
        "\n",
        "\n",
        "def pad_random(x: np.ndarray, max_len: int = 64600):\n",
        "    x_len = x.shape[0]\n",
        "    # if duration is already long enough\n",
        "    if x_len >= max_len:\n",
        "        stt = np.random.randint(x_len - max_len)\n",
        "        return x[stt:stt + max_len]\n",
        "\n",
        "    # if too short\n",
        "    num_repeats = int(max_len / x_len) + 1\n",
        "    padded_x = np.tile(x, (num_repeats))[:max_len]\n",
        "    return padded_x\n",
        "\n",
        "class Dataset_ASVspoof2019_devNeval(Dataset):\n",
        "    def __init__(self, list_IDs, base_dir):\n",
        "        \"\"\"self.list_IDs\t: list of strings (each string: utt key),\n",
        "        \"\"\"\n",
        "        self.list_IDs = list_IDs\n",
        "        self.base_dir = base_dir\n",
        "        self.cut = 64600  # take ~4 sec audio (64600 samples)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_IDs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        key = self.list_IDs[index]\n",
        "        X, _ = sf.read(f\"{self.base_dir}/{key}\")\n",
        "        X_pad = pad(X, self.cut)\n",
        "        x_inp = Tensor(X_pad)\n",
        "        return x_inp, key"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-16T15:19:52.925012Z",
          "iopub.execute_input": "2022-03-16T15:19:52.926057Z",
          "iopub.status.idle": "2022-03-16T15:19:52.937406Z",
          "shell.execute_reply.started": "2022-03-16T15:19:52.92602Z",
          "shell.execute_reply": "2022-03-16T15:19:52.936274Z"
        },
        "trusted": true,
        "id": "b1Nvenz0opxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_set = Dataset_ASVspoof2019_devNeval(list_IDs=config['file_dev'],\n",
        "                                        base_dir=config['dev_database_path'])\n",
        "dev_loader = DataLoader(dev_set,\n",
        "                        batch_size=config[\"batch_size\"],\n",
        "                        shuffle=False,\n",
        "                        drop_last=False,\n",
        "                        pin_memory=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-16T15:19:56.965746Z",
          "iopub.execute_input": "2022-03-16T15:19:56.966381Z",
          "iopub.status.idle": "2022-03-16T15:19:56.972898Z",
          "shell.execute_reply.started": "2022-03-16T15:19:56.966347Z",
          "shell.execute_reply": "2022-03-16T15:19:56.971573Z"
        },
        "trusted": true,
        "id": "4gCT-Wfdopxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_arr = []\n",
        "idxs = []\n",
        "m = nn.Softmax(dim=1)\n",
        "for data, idx in dev_loader:\n",
        "    data = data.to(device)\n",
        "    with torch.no_grad():\n",
        "        _, bt_preds = pred_model(data)\n",
        "    print(bt_preds)\n",
        "    _, predicted = torch.max(bt_preds.data, 1)\n",
        "    print(predicted)\n",
        "    break\n",
        "    pred_arr.extend(list(predicted.cpu().numpy()))\n",
        "    idxs.extend(idx)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-16T15:37:18.90481Z",
          "iopub.execute_input": "2022-03-16T15:37:18.905137Z",
          "iopub.status.idle": "2022-03-16T15:37:18.995965Z",
          "shell.execute_reply.started": "2022-03-16T15:37:18.905105Z",
          "shell.execute_reply": "2022-03-16T15:37:18.994678Z"
        },
        "trusted": true,
        "id": "qniQrpT1opxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# _df = pd.read_csv('./spcup_2022_eval_part1/spcup_2022_eval_part1/labels_eval_part1.csv')\n",
        "pred_df = pd.DataFrame({'track': idxs, 'label': pred_arr})\n",
        "pred_df.to_csv('./result.csv')\n",
        "\n",
        "pred_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-16T15:21:18.025381Z",
          "iopub.execute_input": "2022-03-16T15:21:18.025747Z",
          "iopub.status.idle": "2022-03-16T15:21:18.083027Z",
          "shell.execute_reply.started": "2022-03-16T15:21:18.025692Z",
          "shell.execute_reply": "2022-03-16T15:21:18.082041Z"
        },
        "trusted": true,
        "id": "-tIuJ5HXopxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tracker.stop()"
      ],
      "metadata": {
        "id": "a6oUX3M_opxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sWEUZfcgeNDZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}