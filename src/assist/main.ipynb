{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "from shutil import copy\n",
    "from typing import Dict, List, Union\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "from data_utils import (Dataset_ASVspoof2019_train,\n",
    "                        Dataset_ASVspoof2019_devNeval, genSpoof_list)\n",
    "from evaluation import calculate_tDCF_EER\n",
    "from utils import create_optimizer, seed_worker, set_seed, str_to_bool\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_config: Dict, device: torch.device):\n",
    "    \"\"\"Define DNN model architecture\"\"\"\n",
    "    module = import_module(\"models.{}\".format(model_config[\"architecture\"]))\n",
    "    _model = getattr(module, \"Model\")\n",
    "    model = _model(model_config).to(device)\n",
    "    nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "    print(\"no. model params:{}\".format(nb_params))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(\n",
    "        database_path: str,\n",
    "        label_path: str,\n",
    "        config: dict) -> List[torch.utils.data.DataLoader]:\n",
    "    \"\"\"Make PyTorch DataLoaders for train / developement / evaluation\"\"\"\n",
    "    # == dropping part ==\n",
    "    # track = config[\"track\"]\n",
    "    # prefix_2019 = \"ASVspoof2019.{}\".format(track)\n",
    "\n",
    "    # trn_database_path = database_path / \"ASVspoof2019_{}_train/\".format(track)\n",
    "    # dev_database_path = database_path / \"ASVspoof2019_{}_dev/\".format(track)\n",
    "    # eval_database_path = database_path / \"ASVspoof2019_{}_eval/\".format(track)\n",
    "\n",
    "    # trn_list_path = (database_path /\n",
    "    #                  \"ASVspoof2019_{}_cm_protocols/{}.cm.train.trn.txt\".format(\n",
    "    #                      track, prefix_2019))\n",
    "    # dev_trial_path = (database_path /\n",
    "    #                   \"ASVspoof2019_{}_cm_protocols/{}.cm.dev.trl.txt\".format(\n",
    "    #                       track, prefix_2019))\n",
    "    # eval_trial_path = (\n",
    "    #     database_path /\n",
    "    #     \"ASVspoof2019_{}_cm_protocols/{}.cm.eval.trl.txt\".format(\n",
    "    #         track, prefix_2019))\n",
    "\n",
    "    # d_label_trn, file_train = genSpoof_list(dir_meta=trn_list_path,\n",
    "    #                                         is_train=True,\n",
    "    #                                         is_eval=False)\n",
    "    # print(\"no. training files:\", len(file_train))\n",
    "    # =====================\n",
    "\n",
    "    label_df = pd.read_csv(label_path)\n",
    "    X, y = label_df['track'].values, label_df['algorithm'].values\n",
    "    # stratified split dataset into train-validation\n",
    "    # set param as config[\"split_ratio\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "\n",
    "\n",
    "    train_set = Dataset_ASVspoof2019_train(list_IDs=X_train,\n",
    "                                           labels=y_train,\n",
    "                                           base_dir=database_path)\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(seed)\n",
    "    trn_loader = DataLoader(train_set,\n",
    "                            batch_size=config[\"batch_size\"],\n",
    "                            shuffle=True,\n",
    "                            drop_last=True,\n",
    "                            pin_memory=True,\n",
    "                            worker_init_fn=seed_worker,\n",
    "                            generator=gen)\n",
    "\n",
    "    # # == test dataset not yet given ==\n",
    "\n",
    "    # _, file_dev = genSpoof_list(dir_meta=dev_trial_path,\n",
    "    #                             is_train=False,\n",
    "    #                             is_eval=False)\n",
    "    # print(\"no. validation files:\", len(file_dev))\n",
    "\n",
    "    # dev_set = Dataset_ASVspoof2019_devNeval(list_IDs=file_dev,\n",
    "    #                                         base_dir=dev_database_path)\n",
    "    # dev_loader = DataLoader(dev_set,\n",
    "    #                         batch_size=config[\"batch_size\"],\n",
    "    #                         shuffle=False,\n",
    "    #                         drop_last=False,\n",
    "    #                         pin_memory=True)\n",
    "    # =================================\n",
    "\n",
    "    # == validation dataset {updated} == \n",
    "\n",
    "    eval_set = Dataset_ASVspoof2019_train(list_IDs=X_test,\n",
    "                                           labels=y_test,\n",
    "                                           base_dir=database_path)\n",
    "    eval_loader = DataLoader(eval_set,\n",
    "                             batch_size=config[\"batch_size\"],\n",
    "                             shuffle=False,\n",
    "                             drop_last=False,\n",
    "                             pin_memory=True,\n",
    "                             worker_init_fn=seed_worker,\n",
    "                             generator=gen)\n",
    "\n",
    "    return trn_loader, eval_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_evaluation_file(\n",
    "    data_loader: DataLoader,\n",
    "    model,\n",
    "    device: torch.device,\n",
    "    save_path: str,\n",
    "    trial_path: str) -> None:\n",
    "    \"\"\"Perform evaluation and save the score to a file\"\"\"\n",
    "    model.eval()\n",
    "    with open(trial_path, \"r\") as f_trl:\n",
    "        trial_lines = f_trl.readlines()\n",
    "    fname_list = []\n",
    "    score_list = []\n",
    "    for batch_x, utt_id in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, batch_out = model(batch_x)\n",
    "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "        # add outputs\n",
    "        fname_list.extend(utt_id)\n",
    "        score_list.extend(batch_score.tolist())\n",
    "\n",
    "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "    with open(save_path, \"w\") as fh:\n",
    "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "            _, utt_id, _, src, key = trl.strip().split(' ')\n",
    "            assert fn == utt_id\n",
    "            fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n",
    "    print(\"Scores saved to {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    trn_loader: DataLoader,\n",
    "    model,\n",
    "    optim: Union[torch.optim.SGD, torch.optim.Adam],\n",
    "    device: torch.device,\n",
    "    scheduler: torch.optim.lr_scheduler,\n",
    "    config: argparse.Namespace):\n",
    "    \"\"\"Train the model for one epoch\"\"\"\n",
    "    running_loss = 0\n",
    "    num_total = 0.0\n",
    "    ii = 0\n",
    "    model.train()\n",
    "\n",
    "    # set objective (Loss) functions\n",
    "    weight = torch.FloatTensor([0.1, 0.9]).to(device)\n",
    "    # criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for batch_x, batch_y in trn_loader:\n",
    "        batch_size = batch_x.size(0)\n",
    "        num_total += batch_size\n",
    "        ii += 1\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
    "        _, batch_out = model(batch_x)#, Freq_aug=str_to_bool(config[\"freq_aug\"]))\n",
    "        batch_loss = criterion(batch_out, batch_y)\n",
    "        running_loss += batch_loss.item() * batch_size\n",
    "        optim.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if config[\"optim_config\"][\"scheduler\"] in [\"cosine\", \"keras_decay\"]:\n",
    "            scheduler.step()\n",
    "        elif scheduler is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"scheduler error, got:{}\".format(scheduler))\n",
    "\n",
    "    running_loss /= num_total\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(\n",
    "    trn_loader: DataLoader,\n",
    "    model,\n",
    "    device: torch.device,\n",
    "    config: argparse.Namespace):\n",
    "    \"\"\"Train the model for one epoch\"\"\"\n",
    "    running_loss = 0\n",
    "    num_total = 0.0\n",
    "    ii = 0\n",
    "    model.eval()\n",
    "\n",
    "    # set objective (Loss) functions\n",
    "    weight = torch.FloatTensor([0.1, 0.9]).to(device)\n",
    "    # criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for batch_x, batch_y in trn_loader:\n",
    "        batch_size = batch_x.size(0)\n",
    "        num_total += batch_size\n",
    "        ii += 1\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
    "        _, batch_out = model(batch_x, Freq_aug=str_to_bool(config[\"freq_aug\"]))\n",
    "        batch_loss = criterion(batch_out, batch_y)\n",
    "        running_loss += batch_loss.item() * batch_size\n",
    "        \n",
    "    running_loss /= num_total\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"database_path\": \"../../data/spcup_2022_training_part1/\",\n",
    "    \"label_path\": \"../../data/spcup_2022_training_part1/labels.csv\",\n",
    "    \"asv_score_path\": \"ASVspoof2019_LA_asv_scores/ASVspoof2019.LA.asv.eval.gi.trl.scores.txt\",\n",
    "    \"model_path\": \"./models/weights/AASIST.pth\",\n",
    "    \"batch_size\": 24,\n",
    "    \"num_epochs\": 100,\n",
    "    \"loss\": \"CCE\",\n",
    "    \"track\": \"LA\",\n",
    "    \"eval_all_best\": \"True\",\n",
    "    \"eval_output\": \"eval_scores_using_best_dev_model.txt\",\n",
    "    \"cudnn_deterministic_toggle\": \"True\",\n",
    "    \"cudnn_benchmark_toggle\": \"False\",\n",
    "    \"model_config\": {\n",
    "        \"architecture\": \"AASIST\",\n",
    "        \"nb_samp\": 64600,\n",
    "        \"first_conv\": 128,\n",
    "        \"filts\": [70, [1, 32], [32, 32], [32, 64], [64, 64]],\n",
    "        \"gat_dims\": [64, 32],\n",
    "        \"pool_ratios\": [0.5, 0.7, 0.5, 0.5],\n",
    "        \"temperatures\": [2.0, 2.0, 100.0, 100.0]\n",
    "    },\n",
    "    \"optim_config\": {\n",
    "        \"optimizer\": \"adam\", \n",
    "        \"amsgrad\": \"False\",\n",
    "        \"base_lr\": 0.0001,\n",
    "        \"lr_min\": 0.000005,\n",
    "        \"betas\": [0.9, 0.999],\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"scheduler\": \"cosine\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.config = config\n",
    "args.seed = seed\n",
    "args.output_dir = '../../tmp/out'\n",
    "args.comment = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    # define database related paths\n",
    "    output_dir = Path(args.output_dir)\n",
    "    database_path = Path(config[\"database_path\"])\n",
    "    label_path = Path(config['label_path'])\n",
    "\n",
    "    # set device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Device: {}\".format(device))\n",
    "    # if device == \"cpu\":\n",
    "    #     raise ValueError(\"GPU not detected!\")\n",
    "\n",
    "    # define model architecture\n",
    "    model_config = args.config[\"model_config\"]\n",
    "    model = get_model(model_config, device)\n",
    "\n",
    "    # define dataloaders\n",
    "    trn_loader, eval_loader = get_loader(database_path, label_path, config)\n",
    "\n",
    "    # get optimizer and scheduler\n",
    "    optim_config = config[\"optim_config\"]\n",
    "    optim_config[\"epochs\"] = config[\"num_epochs\"]\n",
    "    optim_config[\"steps_per_epoch\"] = len(trn_loader)\n",
    "    optimizer, scheduler = create_optimizer(model.parameters(), optim_config)\n",
    "    optimizer_swa = SWA(optimizer)\n",
    "\n",
    "    # Training\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        print(\"Start training epoch{:03d}\".format(epoch))\n",
    "        training_loss = train_epoch(trn_loader, model, optimizer, device,\n",
    "                                   scheduler, config)\n",
    "        eval_loss = eval_epoch(eval_loader, model, device, config)\n",
    "        print(f'[{epoch}] Training Loss : {training_loss} | Eval Loss : {eval_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "no. model params:298349\n",
      "Start training epoch000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb#ch0000009?line=0'>1</a>\u001b[0m main(args)\n",
      "\u001b[1;32m/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb Cell 9'\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb#ch0000008?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config[\u001b[39m\"\u001b[39m\u001b[39mnum_epochs\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb#ch0000008?line=29'>30</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStart training epoch\u001b[39m\u001b[39m{:03d}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(epoch))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb#ch0000008?line=30'>31</a>\u001b[0m     training_loss \u001b[39m=\u001b[39m train_epoch(trn_loader, model, optimizer, device,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb#ch0000008?line=31'>32</a>\u001b[0m                                scheduler, config)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb#ch0000008?line=32'>33</a>\u001b[0m     eval_loss \u001b[39m=\u001b[39m eval_epoch(eval_loader, model, device, config)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb#ch0000008?line=33'>34</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m] Training Loss : \u001b[39m\u001b[39m{\u001b[39;00mtraining_loss\u001b[39m}\u001b[39;00m\u001b[39m | Eval Loss : \u001b[39m\u001b[39m{\u001b[39;00meval_loss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb Cell 5'\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(trn_loader, model, optim, device, scheduler, config)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb#ch0000004?line=21'>22</a>\u001b[0m batch_x \u001b[39m=\u001b[39m batch_x\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb#ch0000004?line=22'>23</a>\u001b[0m batch_y \u001b[39m=\u001b[39m batch_y\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mint64)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb#ch0000004?line=23'>24</a>\u001b[0m _, batch_out \u001b[39m=\u001b[39m model(batch_x)\u001b[39m#, Freq_aug=str_to_bool(config[\"freq_aug\"]))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb#ch0000004?line=24'>25</a>\u001b[0m batch_loss \u001b[39m=\u001b[39m criterion(batch_out, batch_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nipunpathitage/Documents/nipdepC/SpCup-22-Init/src/assist/main.ipynb#ch0000004?line=25'>26</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m batch_size\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/nipdepC/SpCup-22-Init/src/assist/models/AASIST.py:539\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x, Freq_aug)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Documents/nipdepC/SpCup-22-Init/src/assist/models/AASIST.py?line=534'>535</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselu(x)\n\u001b[1;32m    <a href='file:///~/Documents/nipdepC/SpCup-22-Init/src/assist/models/AASIST.py?line=536'>537</a>\u001b[0m \u001b[39m# get embeddings using encoder\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Documents/nipdepC/SpCup-22-Init/src/assist/models/AASIST.py?line=537'>538</a>\u001b[0m \u001b[39m# (#bs, #filt, #spec, #seq)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/Documents/nipdepC/SpCup-22-Init/src/assist/models/AASIST.py?line=538'>539</a>\u001b[0m e \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[1;32m    <a href='file:///~/Documents/nipdepC/SpCup-22-Init/src/assist/models/AASIST.py?line=540'>541</a>\u001b[0m \u001b[39m# spectral GAT (GAT-S)\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Documents/nipdepC/SpCup-22-Init/src/assist/models/AASIST.py?line=541'>542</a>\u001b[0m e_S, _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(torch\u001b[39m.\u001b[39mabs(e), dim\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)  \u001b[39m# max along time\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/nipdepC/SpCup-22-Init/src/assist/models/AASIST.py:453\u001b[0m, in \u001b[0;36mResidual_block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Documents/nipdepC/SpCup-22-Init/src/assist/models/AASIST.py?line=450'>451</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/Documents/nipdepC/SpCup-22-Init/src/assist/models/AASIST.py?line=451'>452</a>\u001b[0m     out \u001b[39m=\u001b[39m x\n\u001b[0;32m--> <a href='file:///~/Documents/nipdepC/SpCup-22-Init/src/assist/models/AASIST.py?line=452'>453</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    <a href='file:///~/Documents/nipdepC/SpCup-22-Init/src/assist/models/AASIST.py?line=454'>455</a>\u001b[0m \u001b[39m# print('out',out.shape)\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Documents/nipdepC/SpCup-22-Init/src/assist/models/AASIST.py?line=455'>456</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(out)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=444'>445</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=437'>438</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/wave_2/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args: argparse.Namespace) -> None:\n",
    "    \"\"\"\n",
    "    Main function.\n",
    "    Trains, validates, and evaluates the ASVspoof detection model.\n",
    "    \"\"\"\n",
    "    # load experiment configurations\n",
    "    with open(args.config, \"r\") as f_json:\n",
    "        config = json.loads(f_json.read())\n",
    "    model_config = config[\"model_config\"]\n",
    "    optim_config = config[\"optim_config\"]\n",
    "    optim_config[\"epochs\"] = config[\"num_epochs\"]\n",
    "    track = config[\"track\"]\n",
    "    assert track in [\"LA\", \"PA\", \"DF\"], \"Invalid track given\"\n",
    "    if \"eval_all_best\" not in config:\n",
    "        config[\"eval_all_best\"] = \"True\"\n",
    "    if \"freq_aug\" not in config:\n",
    "        config[\"freq_aug\"] = \"False\"\n",
    "\n",
    "    # make experiment reproducible\n",
    "    set_seed(args.seed, config)\n",
    "\n",
    "    # define database related paths\n",
    "    output_dir = Path(args.output_dir)\n",
    "    prefix_2019 = \"ASVspoof2019.{}\".format(track)\n",
    "    database_path = Path(config[\"database_path\"])\n",
    "    label_path = Path(config['label_path'])\n",
    "\n",
    "    # define model related paths\n",
    "    model_tag = \"{}_{}_ep{}_bs{}\".format(\n",
    "        track,\n",
    "        os.path.splitext(os.path.basename(args.config))[0],\n",
    "        config[\"num_epochs\"], config[\"batch_size\"])\n",
    "    if args.comment:\n",
    "        model_tag = model_tag + \"_{}\".format(args.comment)\n",
    "    model_tag = output_dir / model_tag\n",
    "    model_save_path = model_tag / \"weights\"\n",
    "    eval_score_path = model_tag / config[\"eval_output\"]\n",
    "    if False:\n",
    "        writer = SummaryWriter(model_tag)\n",
    "\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "    copy(args.config, model_tag / \"config.conf\")\n",
    "\n",
    "    # set device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Device: {}\".format(device))\n",
    "    if device == \"cpu\":\n",
    "        raise ValueError(\"GPU not detected!\")\n",
    "\n",
    "    # define model architecture\n",
    "    model = get_model(model_config, device)\n",
    "\n",
    "    # define dataloaders\n",
    "    trn_loader, dev_loader = get_loader(database_path, label_path, config)\n",
    "\n",
    "    # == evaluating model ==\n",
    "    # evaluates pretrained model and exit script\n",
    "    # if args.eval:\n",
    "    #     model.load_state_dict(\n",
    "    #         torch.load(config[\"model_path\"], map_location=device))\n",
    "    #     print(\"Model loaded : {}\".format(config[\"model_path\"]))\n",
    "    #     print(\"Start evaluation...\")\n",
    "    #     produce_evaluation_file(eval_loader, model, device,\n",
    "    #                             eval_score_path, eval_trial_path)\n",
    "    #     calculate_tDCF_EER(cm_scores_file=eval_score_path,\n",
    "    #                        asv_score_file=database_path /\n",
    "    #                        config[\"asv_score_path\"],\n",
    "    #                        output_file=model_tag / \"t-DCF_EER.txt\")\n",
    "    #     print(\"DONE.\")\n",
    "    #     eval_eer, eval_tdcf = calculate_tDCF_EER(\n",
    "    #         cm_scores_file=eval_score_path,\n",
    "    #         asv_score_file=database_path / config[\"asv_score_path\"],\n",
    "    #         output_file=model_tag/\"loaded_model_t-DCF_EER.txt\")\n",
    "    #     sys.exit(0)\n",
    "    # ======================\n",
    "\n",
    "    # get optimizer and scheduler\n",
    "    optim_config[\"steps_per_epoch\"] = len(trn_loader)\n",
    "    optimizer, scheduler = create_optimizer(model.parameters(), optim_config)\n",
    "    optimizer_swa = SWA(optimizer)\n",
    "\n",
    "    best_dev_eer = 1.\n",
    "    best_eval_eer = 100.\n",
    "    best_dev_tdcf = 0.05\n",
    "    best_eval_tdcf = 1.\n",
    "    n_swa_update = 0  # number of snapshots of model to use in SWA\n",
    "    f_log = open(model_tag / \"metric_log.txt\", \"a\")\n",
    "    f_log.write(\"=\" * 5 + \"\\n\")\n",
    "\n",
    "    # make directory for metric logging\n",
    "    metric_path = model_tag / \"metrics\"\n",
    "    os.makedirs(metric_path, exist_ok=True)\n",
    "\n",
    "    # Training\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        print(\"Start training epoch{:03d}\".format(epoch))\n",
    "        running_loss = train_epoch(trn_loader, model, optimizer, device,\n",
    "                                   scheduler, config)\n",
    "        produce_evaluation_file(dev_loader, model, device,\n",
    "                                metric_path/\"dev_score.txt\", dev_trial_path)\n",
    "        dev_eer, dev_tdcf = calculate_tDCF_EER(\n",
    "            cm_scores_file=metric_path/\"dev_score.txt\",\n",
    "            asv_score_file=database_path/config[\"asv_score_path\"],\n",
    "            output_file=metric_path/\"dev_t-DCF_EER_{}epo.txt\".format(epoch),\n",
    "            printout=False)\n",
    "        print(\"DONE.\\nLoss:{:.5f}, dev_eer: {:.3f}, dev_tdcf:{:.5f}\".format(\n",
    "            running_loss, dev_eer, dev_tdcf))\n",
    "        \n",
    "        if False:\n",
    "            writer.add_scalar(\"loss\", running_loss, epoch)\n",
    "            writer.add_scalar(\"dev_eer\", dev_eer, epoch)\n",
    "            writer.add_scalar(\"dev_tdcf\", dev_tdcf, epoch)\n",
    "\n",
    "        best_dev_tdcf = min(dev_tdcf, best_dev_tdcf)\n",
    "        if best_dev_eer >= dev_eer:\n",
    "            print(\"best model find at epoch\", epoch)\n",
    "            best_dev_eer = dev_eer\n",
    "            torch.save(model.state_dict(),\n",
    "                       model_save_path / \"epoch_{}_{:03.3f}.pth\".format(epoch, dev_eer))\n",
    "\n",
    "            # do evaluation whenever best model is renewed\n",
    "            if str_to_bool(config[\"eval_all_best\"]):\n",
    "                produce_evaluation_file(eval_loader, model, device,\n",
    "                                        eval_score_path, eval_trial_path)\n",
    "                eval_eer, eval_tdcf = calculate_tDCF_EER(\n",
    "                    cm_scores_file=eval_score_path,\n",
    "                    asv_score_file=database_path / config[\"asv_score_path\"],\n",
    "                    output_file=metric_path /\n",
    "                    \"t-DCF_EER_{:03d}epo.txt\".format(epoch))\n",
    "\n",
    "                log_text = \"epoch{:03d}, \".format(epoch)\n",
    "                if eval_eer < best_eval_eer:\n",
    "                    log_text += \"best eer, {:.4f}%\".format(eval_eer)\n",
    "                    best_eval_eer = eval_eer\n",
    "                if eval_tdcf < best_eval_tdcf:\n",
    "                    log_text += \"best tdcf, {:.4f}\".format(eval_tdcf)\n",
    "                    best_eval_tdcf = eval_tdcf\n",
    "                    torch.save(model.state_dict(),\n",
    "                               model_save_path / \"best.pth\")\n",
    "                if len(log_text) > 0:\n",
    "                    print(log_text)\n",
    "                    f_log.write(log_text + \"\\n\")\n",
    "\n",
    "            print(\"Saving epoch {} for swa\".format(epoch))\n",
    "            optimizer_swa.update_swa()\n",
    "            n_swa_update += 1\n",
    "        \n",
    "        if False:\n",
    "            writer.add_scalar(\"best_dev_eer\", best_dev_eer, epoch)\n",
    "            writer.add_scalar(\"best_dev_tdcf\", best_dev_tdcf, epoch)\n",
    "\n",
    "    print(\"Start final evaluation\")\n",
    "    epoch += 1\n",
    "    if n_swa_update > 0:\n",
    "        optimizer_swa.swap_swa_sgd()\n",
    "        optimizer_swa.bn_update(trn_loader, model, device=device)\n",
    "    produce_evaluation_file(eval_loader, model, device, eval_score_path,\n",
    "                            eval_trial_path)\n",
    "    eval_eer, eval_tdcf = calculate_tDCF_EER(cm_scores_file=eval_score_path,\n",
    "                                             asv_score_file=database_path /\n",
    "                                             config[\"asv_score_path\"],\n",
    "                                             output_file=model_tag / \"t-DCF_EER.txt\")\n",
    "    f_log = open(model_tag / \"metric_log.txt\", \"a\")\n",
    "    f_log.write(\"=\" * 5 + \"\\n\")\n",
    "    f_log.write(\"EER: {:.3f}, min t-DCF: {:.5f}\".format(eval_eer, eval_tdcf))\n",
    "    f_log.close()\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               model_save_path / \"swa.pth\")\n",
    "\n",
    "    if eval_eer <= best_eval_eer:\n",
    "        best_eval_eer = eval_eer\n",
    "    if eval_tdcf <= best_eval_tdcf:\n",
    "        best_eval_tdcf = eval_tdcf\n",
    "        torch.save(model.state_dict(),\n",
    "                   model_save_path / \"best.pth\")\n",
    "    print(\"Exp FIN. EER: {:.3f}, min t-DCF: {:.5f}\".format(\n",
    "        best_eval_eer, best_eval_tdcf))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4342e088104506c762c0bda77e093724389a62f7580ab4d8d79c756006761a67"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('wave_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
