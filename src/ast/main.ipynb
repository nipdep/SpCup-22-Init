{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import ast\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "basepath = os.path.dirname(os.path.dirname(sys.path[0]))\n",
    "sys.path.append(basepath)\n",
    "import dataloader\n",
    "from models import ASTModel\n",
    "import numpy as np\n",
    "from traintest import train, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "\n",
    "args.data_train = '../../data/final_train_data.json'\n",
    "args.data_val = '../../data/final_test_data.json'\n",
    "args.data_eval = '.json'\n",
    "args.n_class = 6\n",
    "args.model = 'ast'\n",
    "args.dataset = 'speechcommands'\n",
    "args.exp_dir = 'tmp/out'\n",
    "args.lr = 0.001\n",
    "args.optim = 'adam'\n",
    "args.batch_size = 12\n",
    "args.num_workers =32\n",
    "args.n_epochs = 3\n",
    "args.lr_patience = 2\n",
    "args.n_print_steps = 100\n",
    "args.save_model = None # \n",
    "args.freqm = 0\n",
    "args.timem = 0\n",
    "args.mixup = 0\n",
    "args.bal = False\n",
    "args.fstride = 10\n",
    "args.tstride = 10\n",
    "args.imagenet_pretrain = True\n",
    "args.audioset_pretrain = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset spectrogram mean and std, used to normalize the input\n",
    "norm_stats = {'audioset':[-4.2677393, 4.5689974], 'esc50':[-6.6268077, 5.358466], 'speechcommands':[-6.845978, 5.5654526]}\n",
    "target_length = {'audioset':1024, 'esc50':512, 'speechcommands':128}\n",
    "# if add noise for data augmentation, only use for speech commands\n",
    "noise = {'audioset': False, 'esc50': False, 'speechcommands':True}\n",
    "\n",
    "audio_conf = {'num_mel_bins': 128, 'target_length': target_length[args.dataset], 'freqm': args.freqm, 'timem': args.timem, 'mixup': args.mixup, 'dataset': args.dataset, 'mode':'train', 'mean':norm_stats[args.dataset][0], 'std':norm_stats[args.dataset][1],\n",
    "                'noise':noise[args.dataset]}\n",
    "val_audio_conf = {'num_mel_bins': 128, 'target_length': target_length[args.dataset], 'freqm': 0, 'timem': 0, 'mixup': 0, 'dataset': args.dataset, 'mode':'evaluation', 'mean':norm_stats[args.dataset][0], 'std':norm_stats[args.dataset][1], 'noise':False}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced sampler is not used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process speechcommands\n",
      "use dataset mean -6.846 and std 5.565 to normalize the input.\n",
      "now use noise augmentation\n",
      "number of classes is 6\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process speechcommands\n",
      "use dataset mean -6.846 and std 5.565 to normalize the input.\n",
      "number of classes is 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deela\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:478: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "if args.bal == 'bal':\n",
    "    print('balanced sampler is being used')\n",
    "    samples_weight = np.loadtxt(args.data_train[:-5]+'_weight.csv', delimiter=',')\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataloader.AudiosetDataset(args.data_train, audio_conf=audio_conf),\n",
    "        batch_size=args.batch_size, sampler=sampler, num_workers=args.num_workers, pin_memory=True)\n",
    "else:\n",
    "    print('balanced sampler is not used')\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataloader.AudiosetDataset(args.data_train, audio_conf=audio_conf),\n",
    "        batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataloader.AudiosetDataset(args.data_val, audio_conf=val_audio_conf),\n",
    "    batch_size=args.batch_size*2, shuffle=False, num_workers=args.num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_384-d0272ac0.pth\" to ../../pretrained_models\\hub\\checkpoints\\deit_base_distilled_patch16_384-d0272ac0.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequncey stride=10, time stride=10\n",
      "number of patches=144\n"
     ]
    }
   ],
   "source": [
    "audio_model = ASTModel(label_dim=args.n_class, fstride=args.fstride, tstride=args.tstride, input_fdim=128,\n",
    "                                input_tdim=target_length[args.dataset], imagenet_pretrain=args.imagenet_pretrain,\n",
    "                                audioset_pretrain=args.audioset_pretrain, model_size='base384')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now starting training for 3 epochs\n",
      "running on cuda\n",
      "Total parameter number is : 86.911 million\n",
      "Total trainable parameter number is : 86.911 million\n",
      "scheduler for speech commands is used\n",
      "now training with speechcommands, main metrics: acc, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x000002387BE0A340>\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2022-03-05 15:01:00.046424\n",
      "current #epochs=1, #steps=0\n"
     ]
    }
   ],
   "source": [
    "print('Now starting training for {:d} epochs'.format(args.n_epochs))\n",
    "train(audio_model, train_loader, val_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aacd9efd2e917f2085b49ad3eecd2bc8a974d0bb8b89bc48afae7fa44e9f517f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
