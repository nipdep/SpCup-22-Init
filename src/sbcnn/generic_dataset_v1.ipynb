{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import tensorflow.keras.backend as K  \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/spcup_2022_training_part1'\n",
    "Labeled_dir = '../data/spcup_2022_training_part1/labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectDataset:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    def decode_audio(self, audio_binary):\n",
    "        # Decode WAV-encoded audio files to `float32` tensors, normalized\n",
    "        # to the [-1.0, 1.0] range. Return `float32` audio and a sample rate.\n",
    "        audio, _ = tf.audio.decode_wav(contents=audio_binary)\n",
    "        # Since all the data is single channel (mono), drop the `channels`\n",
    "        # axis from the array.\n",
    "        return tf.squeeze(audio, axis=-1)\n",
    "\n",
    "    def get_waveform(self, file_path):\n",
    "        cpath = self.DATA_PATH + os.sep + file_path\n",
    "        audio_binary = tf.io.read_file(cpath)\n",
    "        waveform = self.decode_audio(audio_binary)\n",
    "        return waveform\n",
    "\n",
    "    def waveform_mapper(self, ds):\n",
    "        return ds.map(\n",
    "                # map_func=lambda x: tf.py_function(func=self.get_waveform, inp=[x], Tout=(tf.float32, tf.int64)),\n",
    "                # map_func=lambda x,y: (tf.py_function(self.get_waveform, [x], tf.float32), y),\n",
    "                map_func=lambda x,y: (self.get_waveform(x), y),\n",
    "                num_parallel_calls=self.AUTOTUNE)\n",
    "\n",
    "    def get_spectrogram(self, waveform):\n",
    "        # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "        input_len = self.sptr_len\n",
    "        waveform = waveform[:input_len]\n",
    "        zero_padding = tf.zeros(\n",
    "            [input_len] - tf.shape(waveform),\n",
    "            dtype=tf.float32)\n",
    "        # Cast the waveform tensors' dtype to float32.\n",
    "        waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "        # Concatenate the waveform with `zero_padding`, which ensures all audio\n",
    "        # clips are of the same length.\n",
    "        equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "        # Convert the waveform to a spectrogram via a STFT.\n",
    "        spectrogram = tf.signal.stft(\n",
    "            equal_length, frame_length=255, frame_step=128)\n",
    "        # Obtain the magnitude of the STFT.\n",
    "        spectrogram = tf.abs(spectrogram)\n",
    "        # Add a `channels` dimension, so that the spectrogram can be used\n",
    "        # as image-like input data with convolution layers (which expect\n",
    "        # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "        spectrogram = spectrogram[..., tf.newaxis]\n",
    "        return spectrogram\n",
    "\n",
    "    def spectrogram_mapper(self, ds):\n",
    "        return ds.map(\n",
    "                # map_func=lambda x: tf.py_function(func=self.get_spectrogram, inp=[x], Tout=(tf.float32, tf.int64)),\n",
    "                # map_func=lambda x,y: (tf.py_function(self.get_spectrogram, [x], tf.float32), y),\n",
    "                map_func=lambda x,y: (self.get_spectrogram(x), y),\n",
    "                num_parallel_calls=self.AUTOTUNE)\n",
    "\n",
    "    def load_dataset(self, path, split_ratio):\n",
    "        label_df = pd.read_csv(path)\n",
    "        X, y = label_df['track'].values, label_df['algorithm'].values\n",
    "        # stratified split dataset into train-validation\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=split_ratio)\n",
    "\n",
    "        X_train = tf.convert_to_tensor(X_train)\n",
    "        y_train = tf.convert_to_tensor(y_train)\n",
    "        X_test = tf.convert_to_tensor(X_test)\n",
    "        y_test = tf.convert_to_tensor(y_test)\n",
    "\n",
    "        primary_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "        prm_val_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "        return primary_ds, prm_val_ds\n",
    "    \n",
    "    def call(self, data_path, label_path, sptr_len=16000, BUFFER_SIZE=32000, BATCH_SIZE=32, split_raio=0.2, is_cache=True, is_prefetch=True):\n",
    "        self.sptr_len = sptr_len\n",
    "        self.DATA_PATH = data_path\n",
    "        train_ds, val_ds = self.load_dataset(label_path, split_raio)\n",
    "        train_ds, val_ds = self.waveform_mapper(train_ds), self.waveform_mapper(val_ds)\n",
    "        train_ds, val_ds = self.spectrogram_mapper(train_ds), self.spectrogram_mapper(val_ds)\n",
    "\n",
    "        train_dataset = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=False)\n",
    "        val_dataset = val_ds.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\n",
    "        if is_cache:\n",
    "            train_dataset, val_dataset = train_dataset.cache(), val_dataset.cache()\n",
    "        \n",
    "        if is_prefetch:\n",
    "            train_dataset, val_dataset = train_dataset.prefetch(self.AUTOTUNE), val_dataset.prefetch(self.AUTOTUNE)\n",
    "        \n",
    "        return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = SpectDataset()\n",
    "train_ds, val_ds = dataloader.call(DATA_PATH, Labeled_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, None, 129, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test the dataset on sample model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers  \n",
    "from tensorflow.keras import models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (32, 124, 129, 1)\n"
     ]
    }
   ],
   "source": [
    "for spectrogram, _ in train_ds.take(1):\n",
    "  input_shape = spectrogram.shape\n",
    "print('Input shape:', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing (Resizing)         (None, 32, 32, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,625,221\n",
      "Trainable params: 1,625,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the `tf.keras.layers.Normalization` layer.\n",
    "norm_layer = layers.Normalization()\n",
    "# Fit the state of the layer to the spectrograms\n",
    "# with `Normalization.adapt`.\n",
    "norm_layer.adapt(data=train_ds.map(map_func=lambda spec, label: spec))\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape[1:]),\n",
    "    # Downsample the input.\n",
    "    layers.Resizing(32, 32),\n",
    "    # Normalize.\n",
    "    # norm_layer,\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(5),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 25s 121ms/step - loss: 0.9714 - accuracy: 0.6003 - val_loss: 0.5455 - val_accuracy: 0.7790\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.5088 - accuracy: 0.8123 - val_loss: 0.3873 - val_accuracy: 0.8450\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.3573 - accuracy: 0.8565 - val_loss: 0.3339 - val_accuracy: 0.8700\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2914 - accuracy: 0.8805 - val_loss: 0.3375 - val_accuracy: 0.8550\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2453 - accuracy: 0.8963 - val_loss: 0.3249 - val_accuracy: 0.8770\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.1963 - accuracy: 0.9247 - val_loss: 0.3179 - val_accuracy: 0.8730\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.1603 - accuracy: 0.9395 - val_loss: 0.3039 - val_accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.1424 - accuracy: 0.9450 - val_loss: 0.2844 - val_accuracy: 0.8960\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.1262 - accuracy: 0.9525 - val_loss: 0.3386 - val_accuracy: 0.8760\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.1154 - accuracy: 0.9578 - val_loss: 0.3662 - val_accuracy: 0.8870\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aacd9efd2e917f2085b49ad3eecd2bc8a974d0bb8b89bc48afae7fa44e9f517f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
